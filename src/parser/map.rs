/// Generated by rustemo. Do not edit manually!
use std::fmt::Debug;
use std::hash::Hash;
use rustemo::{
    Result, Input as InputT, Lexer, Token, TokenRecognizer as TokenRecognizerT, Parser,
    ParserDefinition, State as StateT, Builder,
};
use rustemo::regex::Regex;
use rustemo::once_cell::sync::Lazy;
use rustemo::StringLexer;
use rustemo::LRBuilder;
use super::map_actions;
use rustemo::{LRParser, LRContext};
use rustemo::Action::{self, Shift, Reduce, Accept};
#[allow(unused_imports)]
use rustemo::debug::{log, logn};
#[allow(unused_imports)]
#[cfg(debug_assertions)]
use rustemo::colored::*;
pub type Input = str;
const STATE_COUNT: usize = 11usize;
const MAX_RECOGNIZERS: usize = 2usize;
#[allow(dead_code)]
const TERMINAL_COUNT: usize = 7usize;
#[allow(clippy::upper_case_acronyms)]
#[derive(Debug, Default, Clone, Copy, PartialEq, Eq, PartialOrd, Ord, Hash)]
pub enum TokenKind {
    #[default]
    STOP,
    IDENTIFIER,
    AT,
    COMMA,
    SEMICOLON,
    OPENBRACKET,
    CLOSEBRACKET,
}
use TokenKind as TK;
impl From<TokenKind> for usize {
    fn from(t: TokenKind) -> Self {
        t as usize
    }
}
#[allow(clippy::enum_variant_names)]
#[derive(Clone, Copy, PartialEq)]
pub enum ProdKind {
    MapP1,
    Association1P1,
    Association1P2,
    AssociationP1,
    NodeIdP1,
    TypeNameP1,
}
use ProdKind as PK;
impl std::fmt::Debug for ProdKind {
    fn fmt(&self, f: &mut std::fmt::Formatter<'_>) -> std::fmt::Result {
        let name = match self {
            ProdKind::MapP1 => "Map: Association1",
            ProdKind::Association1P1 => "Association1: Association1 COMMA Association",
            ProdKind::Association1P2 => "Association1: Association",
            ProdKind::AssociationP1 => "Association: NodeId SEMICOLON TypeName",
            ProdKind::NodeIdP1 => "NodeId: IDENTIFIER",
            ProdKind::TypeNameP1 => "TypeName: IDENTIFIER",
        };
        write!(f, "{name}")
    }
}
#[allow(clippy::upper_case_acronyms)]
#[allow(dead_code)]
#[derive(Clone, Copy, Debug)]
pub enum NonTermKind {
    EMPTY,
    AUG,
    Map,
    Association1,
    Association,
    NodeId,
    TypeName,
}
impl From<ProdKind> for NonTermKind {
    fn from(prod: ProdKind) -> Self {
        match prod {
            ProdKind::MapP1 => NonTermKind::Map,
            ProdKind::Association1P1 => NonTermKind::Association1,
            ProdKind::Association1P2 => NonTermKind::Association1,
            ProdKind::AssociationP1 => NonTermKind::Association,
            ProdKind::NodeIdP1 => NonTermKind::NodeId,
            ProdKind::TypeNameP1 => NonTermKind::TypeName,
        }
    }
}
#[allow(clippy::enum_variant_names)]
#[derive(Default, Clone, Copy, PartialEq, Eq, PartialOrd, Ord)]
pub enum State {
    #[default]
    AUGS0,
    IDENTIFIERS1,
    MapS2,
    Association1S3,
    AssociationS4,
    NodeIdS5,
    COMMAS6,
    SEMICOLONS7,
    AssociationS8,
    IDENTIFIERS9,
    TypeNameS10,
}
impl StateT for State {
    fn default_layout() -> Option<Self> {
        None
    }
}
impl From<State> for usize {
    fn from(s: State) -> Self {
        s as usize
    }
}
impl std::fmt::Debug for State {
    fn fmt(&self, f: &mut std::fmt::Formatter<'_>) -> std::fmt::Result {
        let name = match self {
            State::AUGS0 => "0:AUG",
            State::IDENTIFIERS1 => "1:IDENTIFIER",
            State::MapS2 => "2:Map",
            State::Association1S3 => "3:Association1",
            State::AssociationS4 => "4:Association",
            State::NodeIdS5 => "5:NodeId",
            State::COMMAS6 => "6:COMMA",
            State::SEMICOLONS7 => "7:SEMICOLON",
            State::AssociationS8 => "8:Association",
            State::IDENTIFIERS9 => "9:IDENTIFIER",
            State::TypeNameS10 => "10:TypeName",
        };
        write!(f, "{name}")
    }
}
#[derive(Debug)]
pub enum Symbol {
    Terminal(Terminal),
    NonTerminal(NonTerminal),
}
#[allow(clippy::upper_case_acronyms)]
#[derive(Debug)]
pub enum Terminal {
    IDENTIFIER(map_actions::IDENTIFIER),
    COMMA,
    SEMICOLON,
}
#[derive(Debug)]
pub enum NonTerminal {
    Map(map_actions::Map),
    Association1(map_actions::Association1),
    Association(map_actions::Association),
    NodeId(map_actions::NodeId),
    TypeName(map_actions::TypeName),
}
type ActionFn = fn(token: TokenKind) -> Vec<Action<State, ProdKind>>;
pub struct MapParserDefinition {
    actions: [ActionFn; STATE_COUNT],
    gotos: [fn(nonterm: NonTermKind) -> State; STATE_COUNT],
    token_kinds: [[Option<(TokenKind, bool)>; MAX_RECOGNIZERS]; STATE_COUNT],
}
fn action_aug_s0(token_kind: TokenKind) -> Vec<Action<State, ProdKind>> {
    match token_kind {
        TK::IDENTIFIER => Vec::from(&[Shift(State::IDENTIFIERS1)]),
        _ => vec![],
    }
}
fn action_identifier_s1(token_kind: TokenKind) -> Vec<Action<State, ProdKind>> {
    match token_kind {
        TK::SEMICOLON => Vec::from(&[Reduce(PK::NodeIdP1, 1usize)]),
        _ => vec![],
    }
}
fn action_map_s2(token_kind: TokenKind) -> Vec<Action<State, ProdKind>> {
    match token_kind {
        TK::STOP => Vec::from(&[Accept]),
        _ => vec![],
    }
}
fn action_association1_s3(token_kind: TokenKind) -> Vec<Action<State, ProdKind>> {
    match token_kind {
        TK::STOP => Vec::from(&[Reduce(PK::MapP1, 1usize)]),
        TK::COMMA => Vec::from(&[Shift(State::COMMAS6)]),
        _ => vec![],
    }
}
fn action_association_s4(token_kind: TokenKind) -> Vec<Action<State, ProdKind>> {
    match token_kind {
        TK::STOP => Vec::from(&[Reduce(PK::Association1P2, 1usize)]),
        TK::COMMA => Vec::from(&[Reduce(PK::Association1P2, 1usize)]),
        _ => vec![],
    }
}
fn action_nodeid_s5(token_kind: TokenKind) -> Vec<Action<State, ProdKind>> {
    match token_kind {
        TK::SEMICOLON => Vec::from(&[Shift(State::SEMICOLONS7)]),
        _ => vec![],
    }
}
fn action_comma_s6(token_kind: TokenKind) -> Vec<Action<State, ProdKind>> {
    match token_kind {
        TK::IDENTIFIER => Vec::from(&[Shift(State::IDENTIFIERS1)]),
        _ => vec![],
    }
}
fn action_semicolon_s7(token_kind: TokenKind) -> Vec<Action<State, ProdKind>> {
    match token_kind {
        TK::IDENTIFIER => Vec::from(&[Shift(State::IDENTIFIERS9)]),
        _ => vec![],
    }
}
fn action_association_s8(token_kind: TokenKind) -> Vec<Action<State, ProdKind>> {
    match token_kind {
        TK::STOP => Vec::from(&[Reduce(PK::Association1P1, 3usize)]),
        TK::COMMA => Vec::from(&[Reduce(PK::Association1P1, 3usize)]),
        _ => vec![],
    }
}
fn action_identifier_s9(token_kind: TokenKind) -> Vec<Action<State, ProdKind>> {
    match token_kind {
        TK::STOP => Vec::from(&[Reduce(PK::TypeNameP1, 1usize)]),
        TK::COMMA => Vec::from(&[Reduce(PK::TypeNameP1, 1usize)]),
        _ => vec![],
    }
}
fn action_typename_s10(token_kind: TokenKind) -> Vec<Action<State, ProdKind>> {
    match token_kind {
        TK::STOP => Vec::from(&[Reduce(PK::AssociationP1, 3usize)]),
        TK::COMMA => Vec::from(&[Reduce(PK::AssociationP1, 3usize)]),
        _ => vec![],
    }
}
fn goto_aug_s0(nonterm_kind: NonTermKind) -> State {
    match nonterm_kind {
        NonTermKind::Map => State::MapS2,
        NonTermKind::Association1 => State::Association1S3,
        NonTermKind::Association => State::AssociationS4,
        NonTermKind::NodeId => State::NodeIdS5,
        _ => {
            panic!(
                "Invalid terminal kind ({nonterm_kind:?}) for GOTO state ({:?}).",
                State::AUGS0
            )
        }
    }
}
fn goto_comma_s6(nonterm_kind: NonTermKind) -> State {
    match nonterm_kind {
        NonTermKind::Association => State::AssociationS8,
        NonTermKind::NodeId => State::NodeIdS5,
        _ => {
            panic!(
                "Invalid terminal kind ({nonterm_kind:?}) for GOTO state ({:?}).",
                State::COMMAS6
            )
        }
    }
}
fn goto_semicolon_s7(nonterm_kind: NonTermKind) -> State {
    match nonterm_kind {
        NonTermKind::TypeName => State::TypeNameS10,
        _ => {
            panic!(
                "Invalid terminal kind ({nonterm_kind:?}) for GOTO state ({:?}).",
                State::SEMICOLONS7
            )
        }
    }
}
fn goto_invalid(_nonterm_kind: NonTermKind) -> State {
    panic!("Invalid GOTO entry!");
}
pub(crate) static PARSER_DEFINITION: MapParserDefinition = MapParserDefinition {
    actions: [
        action_aug_s0,
        action_identifier_s1,
        action_map_s2,
        action_association1_s3,
        action_association_s4,
        action_nodeid_s5,
        action_comma_s6,
        action_semicolon_s7,
        action_association_s8,
        action_identifier_s9,
        action_typename_s10,
    ],
    gotos: [
        goto_aug_s0,
        goto_invalid,
        goto_invalid,
        goto_invalid,
        goto_invalid,
        goto_invalid,
        goto_comma_s6,
        goto_semicolon_s7,
        goto_invalid,
        goto_invalid,
        goto_invalid,
    ],
    token_kinds: [
        [Some((TK::IDENTIFIER, false)), None],
        [Some((TK::SEMICOLON, true)), None],
        [Some((TK::STOP, false)), None],
        [Some((TK::STOP, true)), Some((TK::COMMA, true))],
        [Some((TK::STOP, true)), Some((TK::COMMA, true))],
        [Some((TK::SEMICOLON, true)), None],
        [Some((TK::IDENTIFIER, false)), None],
        [Some((TK::IDENTIFIER, false)), None],
        [Some((TK::STOP, true)), Some((TK::COMMA, true))],
        [Some((TK::STOP, true)), Some((TK::COMMA, true))],
        [Some((TK::STOP, true)), Some((TK::COMMA, true))],
    ],
};
impl ParserDefinition<State, ProdKind, TokenKind, NonTermKind> for MapParserDefinition {
    fn actions(&self, state: State, token: TokenKind) -> Vec<Action<State, ProdKind>> {
        PARSER_DEFINITION.actions[state as usize](token)
    }
    fn goto(&self, state: State, nonterm: NonTermKind) -> State {
        PARSER_DEFINITION.gotos[state as usize](nonterm)
    }
    fn expected_token_kinds(&self, state: State) -> Vec<(TokenKind, bool)> {
        PARSER_DEFINITION.token_kinds[state as usize].iter().map_while(|t| *t).collect()
    }
    fn longest_match() -> bool {
        true
    }
    fn grammar_order() -> bool {
        true
    }
}
pub(crate) type Context<'i, I> = LRContext<'i, I, State, TokenKind>;
pub struct MapParser<
    'i,
    I: InputT + ?Sized,
    L: Lexer<'i, Context<'i, I>, State, TokenKind, Input = I>,
    B,
>(
    LRParser<
        'i,
        Context<'i, I>,
        State,
        ProdKind,
        TokenKind,
        NonTermKind,
        MapParserDefinition,
        L,
        B,
        I,
    >,
);
#[allow(dead_code)]
impl<
    'i,
> MapParser<
    'i,
    Input,
    StringLexer<Context<'i, Input>, State, TokenKind, TokenRecognizer, TERMINAL_COUNT>,
    DefaultBuilder,
> {
    pub fn new() -> Self {
        Self(
            LRParser::new(
                &PARSER_DEFINITION,
                State::default(),
                false,
                false,
                StringLexer::new(true, &RECOGNIZERS),
                DefaultBuilder::new(),
            ),
        )
    }
}
#[allow(dead_code)]
impl<'i, I, L, B> Parser<'i, I, Context<'i, I>, State, TokenKind>
for MapParser<'i, I, L, B>
where
    I: InputT + ?Sized + Debug,
    L: Lexer<'i, Context<'i, I>, State, TokenKind, Input = I>,
    B: LRBuilder<'i, I, Context<'i, I>, State, ProdKind, TokenKind>,
{
    type Output = B::Output;
    fn parse(&self, input: &'i I) -> Result<Self::Output> {
        self.0.parse(input)
    }
    fn parse_with_context(
        &self,
        context: &mut Context<'i, I>,
        input: &'i I,
    ) -> Result<Self::Output> {
        self.0.parse_with_context(context, input)
    }
    fn parse_file<'a, F: AsRef<std::path::Path>>(
        &'a mut self,
        file: F,
    ) -> Result<Self::Output>
    where
        'a: 'i,
    {
        self.0.parse_file(file)
    }
}
#[allow(dead_code)]
#[derive(Debug)]
pub enum Recognizer {
    Stop,
    StrMatch(&'static str),
    RegexMatch(Lazy<Regex>),
}
#[allow(dead_code)]
#[derive(Debug)]
pub struct TokenRecognizer(TokenKind, Recognizer);
impl<'i> TokenRecognizerT<'i> for TokenRecognizer {
    fn recognize(&self, input: &'i str) -> Option<&'i str> {
        match &self {
            #[allow(unused_variables)]
            TokenRecognizer(token_kind, Recognizer::StrMatch(s)) => {
                logn!("{} {:?} -- ", "    Recognizing".green(), token_kind);
                if input.starts_with(s) {
                    log!("{}", "recognized".bold().green());
                    Some(s)
                } else {
                    log!("{}", "not recognized".red());
                    None
                }
            }
            #[allow(unused_variables)]
            TokenRecognizer(token_kind, Recognizer::RegexMatch(r)) => {
                logn!("{} {:?} -- ", "    Recognizing".green(), token_kind);
                let match_str = r.find(input);
                match match_str {
                    Some(x) => {
                        let x_str = x.as_str();
                        log!("{} '{}'", "recognized".bold().green(), x_str);
                        Some(x_str)
                    }
                    _ => {
                        log!("{}", "not recognized".red());
                        None
                    }
                }
            }
            TokenRecognizer(_, Recognizer::Stop) => {
                logn!("{} STOP -- ", "    Recognizing".green());
                if input.is_empty() {
                    log!("{}", "recognized".bold().green());
                    Some("")
                } else {
                    log!("{}", "not recognized".red());
                    None
                }
            }
        }
    }
}
pub(crate) static RECOGNIZERS: [TokenRecognizer; TERMINAL_COUNT] = [
    TokenRecognizer(TokenKind::STOP, Recognizer::Stop),
    TokenRecognizer(
        TokenKind::IDENTIFIER,
        Recognizer::RegexMatch(
            Lazy::new(|| { Regex::new(concat!("^", "\\w+")).unwrap() }),
        ),
    ),
    TokenRecognizer(TokenKind::AT, Recognizer::StrMatch("@")),
    TokenRecognizer(TokenKind::COMMA, Recognizer::StrMatch(",")),
    TokenRecognizer(TokenKind::SEMICOLON, Recognizer::StrMatch(":")),
    TokenRecognizer(TokenKind::OPENBRACKET, Recognizer::StrMatch("[")),
    TokenRecognizer(TokenKind::CLOSEBRACKET, Recognizer::StrMatch("]")),
];
pub struct DefaultBuilder {
    res_stack: Vec<Symbol>,
}
impl DefaultBuilder {
    #[allow(dead_code)]
    pub fn new() -> Self {
        Self { res_stack: vec![] }
    }
}
impl Builder for DefaultBuilder {
    type Output = map_actions::Map;
    fn get_result(&mut self) -> Self::Output {
        match self.res_stack.pop().unwrap() {
            Symbol::NonTerminal(NonTerminal::Map(r)) => r,
            _ => panic!("Invalid result on the parse stack!"),
        }
    }
}
impl<'i> LRBuilder<'i, Input, Context<'i, Input>, State, ProdKind, TokenKind>
for DefaultBuilder {
    #![allow(unused_variables)]
    fn shift_action(
        &mut self,
        context: &Context<'i, Input>,
        token: Token<'i, Input, TokenKind>,
    ) {
        let val = match token.kind {
            TokenKind::STOP => panic!("Cannot shift STOP token!"),
            TokenKind::IDENTIFIER => {
                Terminal::IDENTIFIER(map_actions::identifier(context, token))
            }
            TokenKind::COMMA => Terminal::COMMA,
            TokenKind::SEMICOLON => Terminal::SEMICOLON,
            _ => panic!("Shift of unreachable terminal!"),
        };
        self.res_stack.push(Symbol::Terminal(val));
    }
    fn reduce_action(
        &mut self,
        context: &Context<'i, Input>,
        prod: ProdKind,
        prod_len: usize,
    ) {
        let prod = match prod {
            ProdKind::MapP1 => {
                let mut i = self
                    .res_stack
                    .split_off(self.res_stack.len() - 1usize)
                    .into_iter();
                match i.next().unwrap() {
                    Symbol::NonTerminal(NonTerminal::Association1(p0)) => {
                        NonTerminal::Map(map_actions::map_association1(context, p0))
                    }
                    _ => panic!("Invalid symbol parse stack data."),
                }
            }
            ProdKind::Association1P1 => {
                let mut i = self
                    .res_stack
                    .split_off(self.res_stack.len() - 3usize)
                    .into_iter();
                match (i.next().unwrap(), i.next().unwrap(), i.next().unwrap()) {
                    (
                        Symbol::NonTerminal(NonTerminal::Association1(p0)),
                        _,
                        Symbol::NonTerminal(NonTerminal::Association(p1)),
                    ) => {
                        NonTerminal::Association1(
                            map_actions::association1_c1(context, p0, p1),
                        )
                    }
                    _ => panic!("Invalid symbol parse stack data."),
                }
            }
            ProdKind::Association1P2 => {
                let mut i = self
                    .res_stack
                    .split_off(self.res_stack.len() - 1usize)
                    .into_iter();
                match i.next().unwrap() {
                    Symbol::NonTerminal(NonTerminal::Association(p0)) => {
                        NonTerminal::Association1(
                            map_actions::association1_association(context, p0),
                        )
                    }
                    _ => panic!("Invalid symbol parse stack data."),
                }
            }
            ProdKind::AssociationP1 => {
                let mut i = self
                    .res_stack
                    .split_off(self.res_stack.len() - 3usize)
                    .into_iter();
                match (i.next().unwrap(), i.next().unwrap(), i.next().unwrap()) {
                    (
                        Symbol::NonTerminal(NonTerminal::NodeId(p0)),
                        _,
                        Symbol::NonTerminal(NonTerminal::TypeName(p1)),
                    ) => {
                        NonTerminal::Association(
                            map_actions::association_c1(context, p0, p1),
                        )
                    }
                    _ => panic!("Invalid symbol parse stack data."),
                }
            }
            ProdKind::NodeIdP1 => {
                let mut i = self
                    .res_stack
                    .split_off(self.res_stack.len() - 1usize)
                    .into_iter();
                match i.next().unwrap() {
                    Symbol::Terminal(Terminal::IDENTIFIER(p0)) => {
                        NonTerminal::NodeId(map_actions::node_id_identifier(context, p0))
                    }
                    _ => panic!("Invalid symbol parse stack data."),
                }
            }
            ProdKind::TypeNameP1 => {
                let mut i = self
                    .res_stack
                    .split_off(self.res_stack.len() - 1usize)
                    .into_iter();
                match i.next().unwrap() {
                    Symbol::Terminal(Terminal::IDENTIFIER(p0)) => {
                        NonTerminal::TypeName(
                            map_actions::type_name_identifier(context, p0),
                        )
                    }
                    _ => panic!("Invalid symbol parse stack data."),
                }
            }
        };
        self.res_stack.push(Symbol::NonTerminal(prod));
    }
}
